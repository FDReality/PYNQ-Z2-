{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "import cv2\n",
    "import numpy as np\n",
    "import imutils\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%pybind11/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#加载LSTM神经网络加速器和DMA接口\n",
    "from pynq import Overlay, allocate\n",
    "import pynq.lib.dma\n",
    "from pynq import allocate\n",
    "\n",
    "\n",
    "overlay = Overlay('./LSTM_LIP.bit')  # 加载Overlay\n",
    "dma = overlay.axi_dma_0  # 定义DMA对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-8b6dab1acee0>:88: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  data = data_encode.tostring()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784,)\n",
      "377843712\n",
      "Result: 1,\n",
      "(784,)\n",
      "377843712\n",
      "Result: 1,\n",
      "(784,)\n",
      "377843712\n",
      "Result: 1,\n",
      "(784,)\n",
      "377843712\n",
      "Result: 1,\n",
      "(784,)\n",
      "377843712\n",
      "Result: 1,\n",
      "(784,)\n",
      "377843712\n",
      "Result: 1,\n",
      "(784,)\n",
      "377843712\n",
      "Result: 1,\n",
      "(784,)\n",
      "377843712\n",
      "Result: 0,\n",
      "(784,)\n",
      "377843712\n",
      "Result: 0,\n",
      "(784,)\n",
      "377843712\n",
      "Result: 0,\n",
      "(784,)\n",
      "377843712\n",
      "Result: 0,\n",
      "(784,)\n",
      "377843712\n",
      "Result: 0,\n",
      "(784,)\n",
      "377843712\n",
      "Result: 0,\n",
      "(784,)\n",
      "377843712\n",
      "Result: 0,\n",
      "(784,)\n",
      "377843712\n",
      "Result: 0,\n",
      "(784,)\n",
      "377843712\n",
      "Result: 0,\n",
      "(784,)\n",
      "377843712\n",
      "Result: 0,\n",
      "(784,)\n",
      "377843712\n",
      "Result: 1,\n",
      "(784,)\n",
      "377843712\n",
      "Result: 0,\n",
      "(784,)\n",
      "377843712\n",
      "Result: 0,\n",
      "(784,)\n",
      "377843712\n",
      "Result: 0,\n",
      "(784,)\n",
      "377843712\n",
      "Result: 0,\n",
      "(784,)\n",
      "377843712\n",
      "Result: 1,\n",
      "(784,)\n",
      "377843712\n",
      "Result: 0,\n",
      "(784,)\n",
      "377843712\n",
      "Result: 0,\n",
      "(784,)\n",
      "377843712\n",
      "Result: 1,\n",
      "(784,)\n",
      "377843712\n",
      "Result: 0,\n",
      "(784,)\n",
      "377843712\n",
      "Result: 0,\n",
      "(784,)\n",
      "377843712\n",
      "Result: 1,\n",
      "(784,)\n",
      "377843712\n",
      "Result: 0,\n",
      "(784,)\n",
      "377843712\n",
      "Result: 0,\n",
      "(784,)\n",
      "377843712\n",
      "Result: 1,\n",
      "(784,)\n",
      "377843712\n",
      "Result: 0,\n",
      "(784,)\n",
      "377843712\n",
      "Result: 0,\n",
      "(784,)\n",
      "377843712\n",
      "Result: 0,\n",
      "(784,)\n",
      "377843712\n",
      "Result: 1,\n",
      "(784,)\n",
      "377843712\n",
      "Result: 1,\n",
      "(784,)\n",
      "377843712\n",
      "Result: 1,\n",
      "(784,)\n",
      "377843712\n",
      "Result: 0,\n",
      "(784,)\n",
      "377843712\n",
      "Result: 1,\n",
      "(784,)\n",
      "377843712\n",
      "Result: 1,\n",
      "(784,)\n",
      "377843712\n",
      "Result: 0,\n",
      "(784,)\n",
      "377843712\n",
      "Result: 1,\n",
      "(784,)\n",
      "377843712\n",
      "Result: 0,\n",
      "(784,)\n",
      "377843712\n",
      "Result: 1,\n",
      "(784,)\n",
      "377843712\n",
      "Result: 1,\n",
      "(784,)\n",
      "377843712\n",
      "Result: 0,\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-8b6dab1acee0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mframe_vga\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_vga\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m480\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mimg_encode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_vga\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mdata_encode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_encode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_encode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtostring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n",
    "\n",
    "\n",
    "videoIn = cv2.VideoCapture()\n",
    "videoIn.open(0)\n",
    "videoIn.set(3,160)\n",
    "videoIn.set(4,120)\n",
    "#import face data\n",
    "face_cascade = cv2.CascadeClassifier(\n",
    "        '/home/xilinx/jupyter_notebooks/base/video/data/'\n",
    "        'haarcascade_frontalface_default.xml')\n",
    "        #import eye data\n",
    "mouth_cascade = cv2.CascadeClassifier(\n",
    "        '/home/xilinx/jupyter_notebooks/base/video/data/'\n",
    "        'haarcascade_mcs_mouth.xml')\n",
    "\n",
    "test_images = allocate(shape=(784,), dtype=np.float32)\n",
    "\n",
    "IMG_NUM = 1\n",
    "index = [0] * IMG_NUM\n",
    "\n",
    "while True:\n",
    "    ret, frame_vga = videoIn.read()\n",
    "    if (ret):   \n",
    "# 发送数据:\n",
    "        # picture thransform to gray\n",
    "        gray = cv2.cvtColor(frame_vga, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "        # detect face and eyes\n",
    "        \n",
    "        \n",
    "        time_start = time.time()  # 记录开始时间\n",
    "                # function()   执行的程序\n",
    "\n",
    "        for (x,y,w,h) in faces:\n",
    "            #draw rectangle\n",
    "            mh = int(0.6 * h)\n",
    "            cv2.rectangle(frame_vga,(x,y + mh),(x+w,y+h),(255,0,0),2)\n",
    "            roi_gray = gray[y + mh:y + h, x:x+w]\n",
    "            roi_color = frame_vga[y + mh:y + h, x:x+w] \n",
    "            test = gray[y + mh:y + h, x :x+w]\n",
    "            mouths = mouth_cascade.detectMultiScale(roi_gray)\n",
    "        \n",
    "            for (ex,ey,ew,eh) in mouths:\n",
    "                cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "                test = test[ey:ey + eh, ex :ex+ew]\n",
    "                \n",
    "                test1=cv2.resize(test,(28,28))\n",
    "                test1 = test1.flatten()\n",
    "                print(test1.shape)\n",
    "                for i in range(784):\n",
    "                    test_images[i] = test1[i]\n",
    "                print(test_images.physical_address)\n",
    "                out_buf = allocate(shape=(503, 5), dtype = np.float32)\n",
    "                for i in range (IMG_NUM):\n",
    "                    dma.sendchannel.transfer(test_images)  # 调用DMA将待预测图片数据传输到IP核\n",
    "                    dma.recvchannel.transfer(out_buf[index[i]])  # 调用DMA从IP核获取RNN的推导结果\n",
    "                    dma.sendchannel.wait()  # 等待DMA发送完成\n",
    "                    dma.recvchannel.wait()  # 等待DMA接收完成\n",
    "\n",
    "                out_list = np.array(out_buf).tolist()\n",
    "                max_indx = out_list.index(max(out_list))  # 推导结果向量的最大分量的下标即为预测结果\n",
    "                print('Result: %d,' % max_indx)\n",
    "\n",
    "#                 out_buf = allocate(shape=(1, 5), dtype = np.float32)\n",
    "#                 dma.sendchannel.transfer(test_images)  # 调用DMA将待预测图片数据传输到IP核\n",
    "#                 dma.recvchannel.transfer(out_buf)  # 调用DMA从IP核获取RNN的推导结果\n",
    "#                 dma.sendchannel.wait()  # 等待DMA发送完成\n",
    "#                 dma.recvchannel.wait()  # 等待DMA接收完成\n",
    "\n",
    "\n",
    "\n",
    "                    \n",
    "#                 photoname+=1\n",
    "#                 filename = str(photoname) + '.jpg'  # filename为图像名字，将photoname作为编号命名保存的截图\n",
    "#                 \n",
    "#                 cv2.imwrite(filename, test1)  # 截图 前面为放在桌面的路径 frame为此时的图像              \n",
    "#                 print(filename + '保存成功')  # 打印保存成功\n",
    "#                 if(photoname>20):\n",
    "#                     print(photoname)\n",
    "#                     break\n",
    "\n",
    "\n",
    "    \n",
    "        frame_vga=imutils.resize(frame_vga, width=480)\n",
    "        img_encode = cv2.imencode('.jpg', frame_vga)[1]\n",
    "        data_encode = np.array(img_encode)\n",
    "        data = data_encode.tostring()\n",
    "        s.sendto(data, ('192.168.137.1', 6050))\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "#                 photoname+=1\n",
    "#                 filename = str(photoname) + '.jpg'  # filename为图像名字，将photoname作为编号命名保存的截图\n",
    "#                 cv2.imwrite(filename, frame_vga)  # 截图 前面为放在桌面的路径 frame为此时的图像\n",
    "#                 print(filename + '保存成功')  # 打印保存成功\n",
    "\n",
    "\n",
    "# #             if(i>5):  \n",
    "# #                 #print(eyes.shape)\n",
    "# #                 #------------------------------------------------\n",
    "# #                 #test resize\n",
    "# #                 frame_vga=cv2.resize(test1,(1024,768))\n",
    "# #     #           print(img.shape)\n",
    "# #                 b,g,r = cv2.split(test1)\n",
    "# #                 img_rgb = cv2.merge([r,g,b])\n",
    "# #                 cv2.imwrite('31.jpg',test1)\n",
    "# #                 print(\"image save\")\n",
    "# #                 #break while when detected face\n",
    "# #                 #------------------------------------------------   \n",
    "# #                 face_flag = False\n",
    "# #                 break\n",
    "\n",
    "\n",
    "#         # print the result picture\n",
    "#             get_ipython().magic('matplotlib inline') \n",
    "#             plt.imshow(np_frame[:,:,[2,1,0]])\n",
    "#             plt.show()\n",
    "\n",
    "        \n",
    "# 接收数据:\n",
    "\n",
    "        #print(s.recv(1024).decode('utf-8'))\n",
    "\n",
    "s.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
