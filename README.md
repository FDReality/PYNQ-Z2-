# 基于PYNQ-Z2的唇语识别神经网络加速器
# 1.简介
该项目为2022年全国大学生FPGA创新设计竞赛一等奖作品，将此项目开源，感谢GitHub上诸多大佬无私的分享。这是本人第一次使用GitHub开源，如有问题还请多多包涵
具体内容参见另外一个Branch-master，不是很懂Git上这个分支是怎么安排的（进行一个烂的摆）
# 2.项目介绍
1.HLS LSTM网络IP核的搭建，主要由DMA接口设计和主体网络计算推导两部分组成，生成的IP导入Vivado中构建电路。这里想要做详细了解的可以去看Xilinx官方的PYNQ使用教程。其中还包含一个weight文件，可以将其中内容换成自己LSTM网络训练出的权重和偏置。
2.Vivado 电路主要由DMA、LSTM、ZYNQ三个核心组成，具体的连接图可以参考哈工大的深度神经网络结构教学，该项目也是站在“巨人肩膀”上才艰难实现的，这里感谢他们对入门者无微不至的详细讲解。
3.Jupyter Notebook 上面主要包括权重文件和硬件Overlay文件，主体执行程序详见三个.ipynb文件，程序实现功能笼统来说就是三个部分，将PYNQ做为发送端到电脑接受摄像头捕获的图像；opencv抓取嘴部特征；截取嘴部图片通过DMA送入LSTM推导IP核并获得输出结果。
4. Pycharm main.py文件为电脑做为接收端，获取图片并显示。其他三个文件用来建立自己的训练集并进行LSTM模型建立，输出模型的权重和偏置（Pytorch）。另：.m文件是我在Matlab上做数据处理用的，详情可以参考 https://www.cnblogs.com/picassooo/p/13504533.html
# 3. 
